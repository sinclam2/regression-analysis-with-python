{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the previous chapter, we looked at linear regression\n",
    "    - Linear regression is a supervised method for machine learning\n",
    "        - Rooted in statistics\n",
    "        - Forecasts the target using either continous or binary variables\n",
    "    - In simple linear regression, we assume that the relationship between the predictor variable and the target variable is **linear**\n",
    "- In most cases, one predictor variable isn't enough to accurately predict the value of the target variable\n",
    "    - We usually have to consider several predictor variables and how they interact with each other to create an accurate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we expand the number of predictors past one variable, we can **no longer represent the data on a simple plot**\n",
    "\n",
    "- Also, we don't just consider the interaction between each predictor and the target variable\n",
    "    - We now need to consider the interaction **between the different predictor variables**\n",
    "        - This interaction is called **multicollinearity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "# Using multiple features\n",
    "\n",
    "- First, we'll import and prepare all the libraries and data that we'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 10, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "df['target'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_observations = len(df)\n",
    "variables = list(boston.feature_names)\n",
    "X = df.iloc[:,:-1]\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "# Model building using Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall from the last chapter, we need to add an intercept column to $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = sm.OLS(y, Xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model = linear_regression.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 15 Aug 2018</td> <th>  Prob (F-statistic):</th> <td>6.95e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:44:11</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>   36.4911</td> <td>    5.104</td> <td>    7.149</td> <td> 0.000</td> <td>   26.462</td> <td>   46.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>    <td>   -0.1072</td> <td>    0.033</td> <td>   -3.276</td> <td> 0.001</td> <td>   -0.171</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>      <td>    0.0464</td> <td>    0.014</td> <td>    3.380</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>   <td>    0.0209</td> <td>    0.061</td> <td>    0.339</td> <td> 0.735</td> <td>   -0.100</td> <td>    0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>    <td>    2.6886</td> <td>    0.862</td> <td>    3.120</td> <td> 0.002</td> <td>    0.996</td> <td>    4.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>     <td>  -17.7958</td> <td>    3.821</td> <td>   -4.658</td> <td> 0.000</td> <td>  -25.302</td> <td>  -10.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>    3.8048</td> <td>    0.418</td> <td>    9.102</td> <td> 0.000</td> <td>    2.983</td> <td>    4.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>     <td>    0.0008</td> <td>    0.013</td> <td>    0.057</td> <td> 0.955</td> <td>   -0.025</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -1.4758</td> <td>    0.199</td> <td>   -7.398</td> <td> 0.000</td> <td>   -1.868</td> <td>   -1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>     <td>    0.3057</td> <td>    0.066</td> <td>    4.608</td> <td> 0.000</td> <td>    0.175</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>     <td>   -0.0123</td> <td>    0.004</td> <td>   -3.278</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -0.9535</td> <td>    0.131</td> <td>   -7.287</td> <td> 0.000</td> <td>   -1.211</td> <td>   -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    0.0094</td> <td>    0.003</td> <td>    3.500</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>   -0.5255</td> <td>    0.051</td> <td>  -10.366</td> <td> 0.000</td> <td>   -0.625</td> <td>   -0.426</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.029</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 782.015</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>1.54e-170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.276</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     108.1\n",
       "Date:                Wed, 15 Aug 2018   Prob (F-statistic):          6.95e-135\n",
       "Time:                        14:44:11   Log-Likelihood:                -1498.8\n",
       "No. Observations:                 506   AIC:                             3026.\n",
       "Df Residuals:                     492   BIC:                             3085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         36.4911      5.104      7.149      0.000      26.462      46.520\n",
       "CRIM          -0.1072      0.033     -3.276      0.001      -0.171      -0.043\n",
       "ZN             0.0464      0.014      3.380      0.001       0.019       0.073\n",
       "INDUS          0.0209      0.061      0.339      0.735      -0.100       0.142\n",
       "CHAS           2.6886      0.862      3.120      0.002       0.996       4.381\n",
       "NOX          -17.7958      3.821     -4.658      0.000     -25.302     -10.289\n",
       "RM             3.8048      0.418      9.102      0.000       2.983       4.626\n",
       "AGE            0.0008      0.013      0.057      0.955      -0.025       0.027\n",
       "DIS           -1.4758      0.199     -7.398      0.000      -1.868      -1.084\n",
       "RAD            0.3057      0.066      4.608      0.000       0.175       0.436\n",
       "TAX           -0.0123      0.004     -3.278      0.001      -0.020      -0.005\n",
       "PTRATIO       -0.9535      0.131     -7.287      0.000      -1.211      -0.696\n",
       "B              0.0094      0.003      3.500      0.001       0.004       0.015\n",
       "LSTAT         -0.5255      0.051    -10.366      0.000      -0.625      -0.426\n",
       "==============================================================================\n",
       "Omnibus:                      178.029   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              782.015\n",
       "Skew:                           1.521   Prob(JB):                    1.54e-170\n",
       "Kurtosis:                       8.276   Cond. No.                     1.51e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the last chapter, [we discussed what some of these statistics mean](02-Approaching-Simple-Linear-Regression.ipynb#Glossary)\n",
    "\n",
    "- However, we glossed over the Adjusted R-squared since it wasn't applicable for simple linear regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted R-squared\n",
    "\n",
    "- When working with multiple predictor variables, the standard R-squared measure can **become inflated** (i.e. implies the model is better than it truly is)\n",
    "    - The adjusted R-squared statistic **accounts for the complexity of the model** and is therefore a more accurate representation of the predictiveness of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: take the ratio of $\\frac{\\text{R-squared}}{\\text{Adj. R-sqared}}$ and if it's bigger than 1.2, we know we have some redundant variables in our model\n",
    "\n",
    "- In our model above, the ratio is $\\frac{0.741}{0.734}\\approx 1.01$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy coefficients\n",
    "\n",
    "- We also need to check our coefficients\n",
    "    - There's a risk that they'll pick up noisy and non-valuable information\n",
    "- The bad coefficients usually have:\n",
    "    - value close to zero\n",
    "    - large standard error\n",
    "- The best tool to spot them: **t-tests**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we have a coefficient that's close to zero and has a LOW p-value, this means that it's highly unlikely that the variable is useful in making predictions\n",
    "\n",
    "#### Similarly, if we have a coefficient of any value but with a HIGH p-value, this means that it's not very likely that this is the true coefficient for the variable\n",
    "\n",
    "- For example, the p-values for `INDUS` and `AGE` are very high\n",
    "    - This means we should have little confidence in the predictiveness of the model with respect to these variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cond. No.\n",
    "\n",
    "- This value isn't very meaningful for models with a single variable, but becomes significant in our new model\n",
    "- The metric tells us whether the **results are unstable** when trying to optimize using matrix conversion\n",
    "    - This **instability is caused by multicollinearity**\n",
    "- If the Cond. No. value is **greater than 30**, we know that we can't trust the results\n",
    "    - Even a very similar subset of the training data can lead to a vastly different model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "# Correlation Matrix\n",
    "\n",
    "- For the simple linear regression in the last chapter, we calculated the **Pearson correlation coefficient**\n",
    "    - This tells us the linear association between the predictor variable and the target\n",
    "- For more predictor variables, we're still interested in the relationship between each predictor and the target\n",
    "    - **We also have to check, however, the correlation between the different predictor variables**\n",
    "        - We want to discern whether the variance is unique or shared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partial Correlation\n",
    "\n",
    "- This is the **unique** variance between a predictor and the target\n",
    "- This represents the **exclusive contribution** of a variable to predicting the response\n",
    "\n",
    "#### (Multi)Collinearity\n",
    "\n",
    "- This is the **shared** variance\n",
    "- This can be caused when one predictor causes variance in another predictor which causes variance in the target\n",
    "- If we're considering **two** predictors, it's called **collinearity**\n",
    "    - If it's **more than two**, it's called **multicollinearity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From a statistical approach, high levels of multicollinearity will cause matrix inversion to fail\n",
    "    - This means that we can't really trust our coefficients\n",
    "        - The standard errors will be large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If a model's variables are multicollinear, it's hard to tell which predictors are the important ones\n",
    "    - This leads to poor model prediction\n",
    "        - We'll need to crank up the number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Easiest way to check for multicollinearity: a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col7 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col9 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col6 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col7 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col7 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col6 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow8_col9 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col8 {\n",
       "            background-color:  yellow;\n",
       "        }</style>  \n",
       "<table id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6c\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >CRIM</th> \n",
       "        <th class=\"col_heading level0 col1\" >ZN</th> \n",
       "        <th class=\"col_heading level0 col2\" >INDUS</th> \n",
       "        <th class=\"col_heading level0 col3\" >CHAS</th> \n",
       "        <th class=\"col_heading level0 col4\" >NOX</th> \n",
       "        <th class=\"col_heading level0 col5\" >RM</th> \n",
       "        <th class=\"col_heading level0 col6\" >AGE</th> \n",
       "        <th class=\"col_heading level0 col7\" >DIS</th> \n",
       "        <th class=\"col_heading level0 col8\" >RAD</th> \n",
       "        <th class=\"col_heading level0 col9\" >TAX</th> \n",
       "        <th class=\"col_heading level0 col10\" >PTRATIO</th> \n",
       "        <th class=\"col_heading level0 col11\" >B</th> \n",
       "        <th class=\"col_heading level0 col12\" >LSTAT</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6clevel0_row0\" class=\"row_heading level0 row0\" >CRIM</th> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow0_col0\" class=\"data row0 col0\" >1</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow0_col1\" class=\"data row0 col1\" >-0.199458</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow0_col2\" class=\"data row0 col2\" >0.404471</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow0_col3\" class=\"data row0 col3\" >-0.0552953</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow0_col4\" class=\"data row0 col4\" >0.417521</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow0_col5\" class=\"data row0 col5\" >-0.21994</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow0_col6\" class=\"data row0 col6\" >0.350784</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow0_col7\" class=\"data row0 col7\" >-0.377904</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow0_col8\" class=\"data row0 col8\" >0.622029</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow0_col9\" class=\"data row0 col9\" >0.579564</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow0_col10\" class=\"data row0 col10\" >0.28825</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow0_col11\" class=\"data row0 col11\" >-0.377365</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow0_col12\" class=\"data row0 col12\" >0.45222</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6clevel0_row1\" class=\"row_heading level0 row1\" >ZN</th> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow1_col0\" class=\"data row1 col0\" >-0.199458</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow1_col1\" class=\"data row1 col1\" >1</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow1_col2\" class=\"data row1 col2\" >-0.533828</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow1_col3\" class=\"data row1 col3\" >-0.0426967</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow1_col4\" class=\"data row1 col4\" >-0.516604</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow1_col5\" class=\"data row1 col5\" >0.311991</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow1_col6\" class=\"data row1 col6\" >-0.569537</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow1_col7\" class=\"data row1 col7\" >0.664408</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow1_col8\" class=\"data row1 col8\" >-0.311948</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow1_col9\" class=\"data row1 col9\" >-0.314563</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow1_col10\" class=\"data row1 col10\" >-0.391679</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow1_col11\" class=\"data row1 col11\" >0.17552</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow1_col12\" class=\"data row1 col12\" >-0.412995</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6clevel0_row2\" class=\"row_heading level0 row2\" >INDUS</th> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col0\" class=\"data row2 col0\" >0.404471</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col1\" class=\"data row2 col1\" >-0.533828</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col2\" class=\"data row2 col2\" >1</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col3\" class=\"data row2 col3\" >0.062938</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col4\" class=\"data row2 col4\" >0.763651</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col5\" class=\"data row2 col5\" >-0.391676</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col6\" class=\"data row2 col6\" >0.644779</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col7\" class=\"data row2 col7\" >-0.708027</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col8\" class=\"data row2 col8\" >0.595129</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col9\" class=\"data row2 col9\" >0.72076</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col10\" class=\"data row2 col10\" >0.383248</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col11\" class=\"data row2 col11\" >-0.356977</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow2_col12\" class=\"data row2 col12\" >0.6038</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6clevel0_row3\" class=\"row_heading level0 row3\" >CHAS</th> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow3_col0\" class=\"data row3 col0\" >-0.0552953</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow3_col1\" class=\"data row3 col1\" >-0.0426967</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow3_col2\" class=\"data row3 col2\" >0.062938</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow3_col3\" class=\"data row3 col3\" >1</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow3_col4\" class=\"data row3 col4\" >0.0912028</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow3_col5\" class=\"data row3 col5\" >0.0912512</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow3_col6\" class=\"data row3 col6\" >0.0865178</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow3_col7\" class=\"data row3 col7\" >-0.0991758</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow3_col8\" class=\"data row3 col8\" >-0.00736824</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow3_col9\" class=\"data row3 col9\" >-0.0355865</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow3_col10\" class=\"data row3 col10\" >-0.121515</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow3_col11\" class=\"data row3 col11\" >0.0487885</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow3_col12\" class=\"data row3 col12\" >-0.0539293</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6clevel0_row4\" class=\"row_heading level0 row4\" >NOX</th> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col0\" class=\"data row4 col0\" >0.417521</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col1\" class=\"data row4 col1\" >-0.516604</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col2\" class=\"data row4 col2\" >0.763651</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col3\" class=\"data row4 col3\" >0.0912028</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col4\" class=\"data row4 col4\" >1</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col5\" class=\"data row4 col5\" >-0.302188</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col6\" class=\"data row4 col6\" >0.73147</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col7\" class=\"data row4 col7\" >-0.76923</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col8\" class=\"data row4 col8\" >0.611441</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col9\" class=\"data row4 col9\" >0.668023</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col10\" class=\"data row4 col10\" >0.188933</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col11\" class=\"data row4 col11\" >-0.380051</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow4_col12\" class=\"data row4 col12\" >0.590879</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6clevel0_row5\" class=\"row_heading level0 row5\" >RM</th> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow5_col0\" class=\"data row5 col0\" >-0.21994</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow5_col1\" class=\"data row5 col1\" >0.311991</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow5_col2\" class=\"data row5 col2\" >-0.391676</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow5_col3\" class=\"data row5 col3\" >0.0912512</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow5_col4\" class=\"data row5 col4\" >-0.302188</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow5_col5\" class=\"data row5 col5\" >1</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow5_col6\" class=\"data row5 col6\" >-0.240265</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow5_col7\" class=\"data row5 col7\" >0.205246</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow5_col8\" class=\"data row5 col8\" >-0.209847</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow5_col9\" class=\"data row5 col9\" >-0.292048</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow5_col10\" class=\"data row5 col10\" >-0.355501</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow5_col11\" class=\"data row5 col11\" >0.128069</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow5_col12\" class=\"data row5 col12\" >-0.613808</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6clevel0_row6\" class=\"row_heading level0 row6\" >AGE</th> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col0\" class=\"data row6 col0\" >0.350784</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col1\" class=\"data row6 col1\" >-0.569537</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col2\" class=\"data row6 col2\" >0.644779</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col3\" class=\"data row6 col3\" >0.0865178</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col4\" class=\"data row6 col4\" >0.73147</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col5\" class=\"data row6 col5\" >-0.240265</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col6\" class=\"data row6 col6\" >1</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col7\" class=\"data row6 col7\" >-0.747881</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col8\" class=\"data row6 col8\" >0.456022</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col9\" class=\"data row6 col9\" >0.506456</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col10\" class=\"data row6 col10\" >0.261515</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col11\" class=\"data row6 col11\" >-0.273534</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow6_col12\" class=\"data row6 col12\" >0.602339</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6clevel0_row7\" class=\"row_heading level0 row7\" >DIS</th> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col0\" class=\"data row7 col0\" >-0.377904</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col1\" class=\"data row7 col1\" >0.664408</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col2\" class=\"data row7 col2\" >-0.708027</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col3\" class=\"data row7 col3\" >-0.0991758</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col4\" class=\"data row7 col4\" >-0.76923</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col5\" class=\"data row7 col5\" >0.205246</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col6\" class=\"data row7 col6\" >-0.747881</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col7\" class=\"data row7 col7\" >1</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col8\" class=\"data row7 col8\" >-0.494588</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col9\" class=\"data row7 col9\" >-0.534432</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col10\" class=\"data row7 col10\" >-0.232471</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col11\" class=\"data row7 col11\" >0.291512</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow7_col12\" class=\"data row7 col12\" >-0.496996</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6clevel0_row8\" class=\"row_heading level0 row8\" >RAD</th> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow8_col0\" class=\"data row8 col0\" >0.622029</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow8_col1\" class=\"data row8 col1\" >-0.311948</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow8_col2\" class=\"data row8 col2\" >0.595129</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow8_col3\" class=\"data row8 col3\" >-0.00736824</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow8_col4\" class=\"data row8 col4\" >0.611441</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow8_col5\" class=\"data row8 col5\" >-0.209847</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow8_col6\" class=\"data row8 col6\" >0.456022</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow8_col7\" class=\"data row8 col7\" >-0.494588</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow8_col8\" class=\"data row8 col8\" >1</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow8_col9\" class=\"data row8 col9\" >0.910228</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow8_col10\" class=\"data row8 col10\" >0.464741</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow8_col11\" class=\"data row8 col11\" >-0.444413</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow8_col12\" class=\"data row8 col12\" >0.488676</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6clevel0_row9\" class=\"row_heading level0 row9\" >TAX</th> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col0\" class=\"data row9 col0\" >0.579564</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col1\" class=\"data row9 col1\" >-0.314563</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col2\" class=\"data row9 col2\" >0.72076</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col3\" class=\"data row9 col3\" >-0.0355865</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col4\" class=\"data row9 col4\" >0.668023</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col5\" class=\"data row9 col5\" >-0.292048</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col6\" class=\"data row9 col6\" >0.506456</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col7\" class=\"data row9 col7\" >-0.534432</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col8\" class=\"data row9 col8\" >0.910228</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col9\" class=\"data row9 col9\" >1</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col10\" class=\"data row9 col10\" >0.460853</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col11\" class=\"data row9 col11\" >-0.441808</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow9_col12\" class=\"data row9 col12\" >0.543993</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6clevel0_row10\" class=\"row_heading level0 row10\" >PTRATIO</th> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow10_col0\" class=\"data row10 col0\" >0.28825</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow10_col1\" class=\"data row10 col1\" >-0.391679</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow10_col2\" class=\"data row10 col2\" >0.383248</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow10_col3\" class=\"data row10 col3\" >-0.121515</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow10_col4\" class=\"data row10 col4\" >0.188933</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow10_col5\" class=\"data row10 col5\" >-0.355501</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow10_col6\" class=\"data row10 col6\" >0.261515</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow10_col7\" class=\"data row10 col7\" >-0.232471</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow10_col8\" class=\"data row10 col8\" >0.464741</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow10_col9\" class=\"data row10 col9\" >0.460853</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow10_col10\" class=\"data row10 col10\" >1</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow10_col11\" class=\"data row10 col11\" >-0.177383</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow10_col12\" class=\"data row10 col12\" >0.374044</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6clevel0_row11\" class=\"row_heading level0 row11\" >B</th> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow11_col0\" class=\"data row11 col0\" >-0.377365</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow11_col1\" class=\"data row11 col1\" >0.17552</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow11_col2\" class=\"data row11 col2\" >-0.356977</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow11_col3\" class=\"data row11 col3\" >0.0487885</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow11_col4\" class=\"data row11 col4\" >-0.380051</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow11_col5\" class=\"data row11 col5\" >0.128069</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow11_col6\" class=\"data row11 col6\" >-0.273534</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow11_col7\" class=\"data row11 col7\" >0.291512</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow11_col8\" class=\"data row11 col8\" >-0.444413</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow11_col9\" class=\"data row11 col9\" >-0.441808</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow11_col10\" class=\"data row11 col10\" >-0.177383</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow11_col11\" class=\"data row11 col11\" >1</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow11_col12\" class=\"data row11 col12\" >-0.366087</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6clevel0_row12\" class=\"row_heading level0 row12\" >LSTAT</th> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow12_col0\" class=\"data row12 col0\" >0.45222</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow12_col1\" class=\"data row12 col1\" >-0.412995</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow12_col2\" class=\"data row12 col2\" >0.6038</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow12_col3\" class=\"data row12 col3\" >-0.0539293</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow12_col4\" class=\"data row12 col4\" >0.590879</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow12_col5\" class=\"data row12 col5\" >-0.613808</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow12_col6\" class=\"data row12 col6\" >0.602339</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow12_col7\" class=\"data row12 col7\" >-0.496996</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow12_col8\" class=\"data row12 col8\" >0.488676</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow12_col9\" class=\"data row12 col9\" >0.543993</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow12_col10\" class=\"data row12 col10\" >0.374044</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow12_col11\" class=\"data row12 col11\" >-0.366087</td> \n",
       "        <td id=\"T_33e162de_a0bb_11e8_bdc6_0e906c995c6crow12_col12\" class=\"data row12 col12\" >1</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2351c1bdba8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr = X.corr()\n",
    "\n",
    "highlight_vals = lambda x: 'background-color: yellow' if 1>abs(x)>=0.7 else ''\n",
    "\n",
    "df_corr.style.applymap(highlight_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see, some of these correlation values are pretty high\n",
    "    - We can explain some of these pretty easily\n",
    "    \n",
    "- `NOX` represents the amount of pollution\n",
    "- `DIS` represents the distance to employment centers\n",
    "- `INDUS` represents the number of non-residential or commercial buildings in the area\n",
    "- `TAX` represents the property tax rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also use a heat map to visualize these correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolor(df_corr, cmap = 'Greens')\n",
    "ticks, labels = [x+0.5 for x in range(len(df_corr.index))], list(df_corr.index)\n",
    "plt.yticks(ticks, labels)\n",
    "plt.xticks(ticks, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another way to look at multicollinearity: eigenvectors\n",
    "\n",
    "- The eigenvalues that we derive tell us the amound of recombined variance for each additional variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(df_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that we've calculated the eigenvalues, we look at the smallest ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.12265476, 1.43206335, 1.24116299, 0.85779892, 0.83456618,\n",
       "       0.65965056, 0.53901749, 0.39654415, 0.06351553, 0.27743495,\n",
       "       0.16916744, 0.18616388, 0.22025981])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The minimum value of 0.06351553 occurs at index 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06351552722222045"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalues[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's look at the eigenvector in index 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM      -0.045528\n",
       "ZN         0.080899\n",
       "INDUS      0.251267\n",
       "CHAS      -0.035904\n",
       "NOX       -0.043890\n",
       "RM        -0.045805\n",
       "AGE        0.038707\n",
       "DIS        0.018284\n",
       "RAD        0.633373\n",
       "TAX       -0.720243\n",
       "PTRATIO   -0.023509\n",
       "B          0.004850\n",
       "LSTAT     -0.024772\n",
       "Name: 8, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(eigenvectors, index = df_corr.index)[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see, the most significant values in this eigenvector are for\n",
    "    1. `INDUS`\n",
    "    2. `RAD`\n",
    "    3. `TAX`\n",
    "    \n",
    "- **This suggests that these are the most correlated predictor variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "# Gradient descent revisited\n",
    "\n",
    "- In the last section, we [showed the steps of gradient descent](02-Approaching-Simple-Linear-Regression.ipynb#Gradient-descent-at-work)\n",
    "    - When we introduce more variables to the model, the math remains the same\n",
    "- **Note**: as we add more variables to our model, we can't graph the relationship with a simple plot\n",
    "    - We'd need to graph a plane (or hyperplane) which isn't that illustrative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "# Feature scaling\n",
    "\n",
    "- Multicollinearity makes it really hard to invert the matrix in the pseudoinverse method\n",
    "- Gradient descent, however, is **not affected by this problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It's not a perfect method, though\n",
    "\n",
    "- The scales of the features can be different\n",
    "- In our housing example:\n",
    "    - The `RM` variable gives the average number of rooms\n",
    "    - The `NOX` variable gives the percentage of certain pollutants in the air\n",
    "    - The `DIS` variable gives the average distance to the employment centre\n",
    "- When the features have different scales, the optimization will be dominated by the bigger scale variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution: feature scaling\n",
    "\n",
    "- This means **adjusting the variables so their scales are all the same**\n",
    "\n",
    "- There are two ways to achieve feature scaling\n",
    "    1. **Normalization**\n",
    "        - This converts each value to a score between 0 and 1\n",
    "    2. **Standardization**\n",
    "        - This converts each value to its z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We usually stick to standardization\n",
    "    - Reasons:\n",
    "        - Easy to convert back to the original values\n",
    "        - The mean values converted to 0 means the optimization runs faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the `StandardScaler` algorithm in the scikit-learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = standardization.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.417713</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.415269</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.415272</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414680</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.410409</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.417713  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.415269 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.415272 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.414680 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.410409 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fit, columns = X.columns).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's compare these rows to the first 5 of the actual data, as well as the mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.593761</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.596783</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CRIM         ZN      INDUS      CHAS       NOX        RM        AGE  \\\n",
       "mean  3.593761  11.363636  11.136779  0.069170  0.554695  6.284634  68.574901   \n",
       "std   8.596783  23.322453   6.860353  0.253994  0.115878  0.702617  28.148861   \n",
       "\n",
       "           DIS       RAD         TAX    PTRATIO           B      LSTAT  \n",
       "mean  3.795043  9.549407  408.237154  18.455534  356.674032  12.653063  \n",
       "std   2.105710  8.707259  168.537116   2.164946   91.294864   7.141062  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe().loc[['mean','std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Just as an example, the first values in the `CRIM` column was calculated as:\n",
    "\n",
    "### $\\frac{0.00632 - 3.593761}{8.596783} = -0.417713$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before we calculate anything, we need to add a column to our standardized $X$ matrix for the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xst = standardization.fit_transform(X)\n",
    "Xst = np.column_stack((Xst, np.ones(n_observations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For our first step, we generate a bunch of random values as our starting point for $w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.random(Xst.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, we calculate the hypothesis vector $Xw$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = np.matmul(Xst,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then, we calculate the loss as the difference between the hypothesis and the observed values i.e. $Xw - y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = hypothesis - y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, we calculate the gradients by multiplying each column in the matrix $X$ and taking the mean of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = np.mean(loss[:,np.newaxis] * Xst, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And finally, we remove a small portion of the gradients from the vector $w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.02\n",
    "w = w - alpha*gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, we repeat this process until we converge on the coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Let's restart from the beginning and loop through the whole process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.02\n",
    "n_iterations = 20000\n",
    "eta = 10**-12\n",
    "\n",
    "SSL = 10**10\n",
    "\n",
    "w = np.random.random(Xst.shape[1])\n",
    "hypothesis = np.matmul(Xst,w)\n",
    "loss = hypothesis - y\n",
    "gradients = np.mean(loss[:,np.newaxis] * Xst, axis = 0)\n",
    "new_SSL = np.sum(loss**2)\n",
    "\n",
    "\n",
    "i = 1\n",
    "while (i <= n_iterations)&(np.absolute(SSL - new_SSL)>eta):\n",
    "    i += 1\n",
    "    SSL = new_SSL\n",
    "    w = w - alpha*gradients\n",
    "    hypothesis = np.matmul(Xst,w)\n",
    "    loss = hypothesis - y\n",
    "    gradients = np.mean(loss[:,np.newaxis] * Xst, axis = 0)\n",
    "    new_SSL = np.sum(loss**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.920411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>1.080980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.142965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.682204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-2.060092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>2.670642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.021120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-3.104448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>2.658782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-2.075893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-2.062156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.856640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-3.748680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coefficients\n",
       "CRIM          -0.920411\n",
       "ZN             1.080980\n",
       "INDUS          0.142965\n",
       "CHAS           0.682204\n",
       "NOX           -2.060092\n",
       "RM             2.670642\n",
       "AGE            0.021120\n",
       "DIS           -3.104448\n",
       "RAD            2.658782\n",
       "TAX           -2.075893\n",
       "PTRATIO       -2.062156\n",
       "B              0.856640\n",
       "LSTAT         -3.748680\n",
       "intercept     22.532806"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(w, index = list(X.columns) + ['intercept'], columns = ['coefficients'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Even though we have more variables, this calculation is faster\n",
    "    - This is caused by standardizing the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So, we can't just use these values right away\n",
    "    - We need to rescale them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "# Understanding coefficients\n",
    "\n",
    "- $\\hat{y}$ is defined as:\n",
    "\n",
    "# $\\hat{y} = \\beta_{0} + \\sum\\beta_{i}x_{i}$\n",
    "\n",
    "- The values we derived above need to be rescaled. The calculation is:\n",
    "\n",
    "# $\\hat{y} = \\tilde{\\beta_{0}} + \\sum\\frac{\\tilde{\\beta_{i}}(x_{i}-\\bar{x}_{i})}{\\delta_{i}}$\n",
    "\n",
    "- where $\\delta_{i}$ is the standard deviation of the standardized $x_{i}$ and $\\tilde{\\beta_{i}}$ is the derived beta for standardized $x_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, if we separate the $x_{i}$ from the $\\bar{x_{i}}$ in the formula above, we can express $\\beta_{0}$ as a function of the $\\tilde{\\beta_{i}}$s and $\\delta_{i}$s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\hat{y} = \\left (\\tilde{\\beta_{0}} + \\sum\\frac{\\tilde{\\beta_{i}}\\bar{x}_{i}}{\\delta_{i}} \\right ) + \\sum\\left ( \\frac{\\tilde{\\beta_{i}}}{\\delta_{i}} x_{i} \\right ) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From this, we can express each term as:\n",
    "\n",
    "# $\\beta_{0} = \\tilde{\\beta_{0}} + \\sum\\frac{\\tilde{\\beta_{i}}\\bar{x}_{i}}{\\delta_{i}}$\n",
    "\n",
    "# $\\beta_{i} = \\frac{\\tilde{\\beta_{i}}}{\\delta_{i}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_betas = w[:-1]\n",
    "derived_intercept = w[-1]\n",
    "x_bars = standardization.mean_\n",
    "deltas = standardization.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0 = derived_intercept - np.sum((derived_betas*x_bars)/deltas)\n",
    "beta_is = derived_betas/deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unstandardized coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.107171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.046395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.020860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>2.688562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-17.795756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.804753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.475759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.305655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.953463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.009393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.525467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>36.491094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           unstandardized coefficients\n",
       "CRIM                         -0.107171\n",
       "ZN                            0.046395\n",
       "INDUS                         0.020860\n",
       "CHAS                          2.688562\n",
       "NOX                         -17.795756\n",
       "RM                            3.804753\n",
       "AGE                           0.000751\n",
       "DIS                          -1.475759\n",
       "RAD                           0.305655\n",
       "TAX                          -0.012329\n",
       "PTRATIO                      -0.953463\n",
       "B                             0.009393\n",
       "LSTAT                        -0.525467\n",
       "intercept                    36.491094"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(beta_is)+[beta_0], index = list(X.columns) + ['intercept'], columns = ['unstandardized coefficients'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These are the proper beta values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "# Estimating feature importance\n",
    "\n",
    "- The easiest and most basic way to understand the model we've derived is to **check the signs**\n",
    "    - If we expect the predictor to decrease the target variable as it increases, then we should expect a negative sign\n",
    "        - E.g. if we're predicting home prices in a neighborhood and one of the predictors is crime rate, we'd expect the house prices to decrease as the crime rate increases therefore the beta for that predictor should be negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the sign of the beta is the **opposite of what we expected**, it's called a **reversal**\n",
    "    - Reversals are not uncommon and can reveal the way things actually interact\n",
    "    - However, sometimes **multicollinearity between predictors can increase uncertainty of estimates**\n",
    "        - This can cause signs to switch back and forth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consequently, we shouldn't jump to any conclusions when we get the regression results\n",
    "\n",
    "### Instead, we should pull apart the model and inspect the statistical measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once we've looked at the signs of the beta values, we can check for the **impact of each variable on the model**\n",
    "    - This tells us how much of the predicted result is **dominated by variations in a single feature**\n",
    "        - If a predictor's impact is low, reversals and other difficuties are less of a big deal\n",
    "            - Sometimes, we can just ignore them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we inspect the impact of each variable, we can make our model more economical by removing unnecessary features\n",
    "\n",
    "- We can rank predictors to make our model simpler by removing the least important ones\n",
    "    - **Why do we want a simpler model?**\n",
    "        - Less prone to errors\n",
    "        - Easier to understand\n",
    "        - *Recall*: Occam's Razor says that if two models explain something equally well, pick the simpler one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "\n",
    "# Inspecting standardzied coefficients\n",
    "\n",
    "- After we've standardized the observations, each value represents a z-score\n",
    "    - This means we're using a similar yard stick for each variable\n",
    "\n",
    "- Let's look at the Boston dataset to see what this means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we'll look at our non-standardized coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = linear_model.LinearRegression(normalize=False, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>17.795759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.804752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>2.688561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>1.475759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.953464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.525467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.305655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>0.107171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.046395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.020860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.009393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              coef\n",
       "NOX      17.795759\n",
       "RM        3.804752\n",
       "CHAS      2.688561\n",
       "DIS       1.475759\n",
       "PTRATIO   0.953464\n",
       "LSTAT     0.525467\n",
       "RAD       0.305655\n",
       "CRIM      0.107171\n",
       "ZN        0.046395\n",
       "INDUS     0.020860\n",
       "TAX       0.012329\n",
       "B         0.009393\n",
       "AGE       0.000751"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(linear_regression.coef_, index = X.columns, columns = ['coef']).abs()).sort_values('coef', ascending = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at these values, it looks like `NOX` is by far the most important variable\n",
    "\n",
    "- But remember, **these variables have different scales**\n",
    "\n",
    "### Let's rerun the regression, but we'll use the standardized variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "standardization = StandardScaler()\n",
    "stand_coef_lin_reg = make_pipeline(standardization, linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: the `make_pipeline` wrapper defines the operations performed on the data before feeding it into the regression\n",
    "\n",
    "- This means that we use the `StandardScaler` to standardize the variables before they're fed in\n",
    "    - Therefore, our regression coefficients will be standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>3.748680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>3.104448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>2.670641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>2.658787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>2.075898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>2.062156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>2.060092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>1.080981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>0.920411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.856640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.682203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.142967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.021121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef\n",
       "LSTAT    3.748680\n",
       "DIS      3.104448\n",
       "RM       2.670641\n",
       "RAD      2.658787\n",
       "TAX      2.075898\n",
       "PTRATIO  2.062156\n",
       "NOX      2.060092\n",
       "ZN       1.080981\n",
       "CRIM     0.920411\n",
       "B        0.856640\n",
       "CHAS     0.682203\n",
       "INDUS    0.142967\n",
       "AGE      0.021121"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(stand_coef_lin_reg.fit(X,y).steps[1][1].coef_, index = X.columns, \n",
    "              columns = ['coef']).abs()).sort_values('coef', ascending = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we've standardized our variables, the order as changed\n",
    "\n",
    "- This means that a single unit change of `LSTAT` is changes our results way more than a single unit change in `ZN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does this mean that we fully understand which variables are most important?\n",
    "    - **NO!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "# Comparing models by R-squared\n",
    "\n",
    "- Simply put, the R-squared statistic tells us how accurate our model is\n",
    "    - The higher the R-sqared value, the better\n",
    "    \n",
    "- We can therefore compare the accuracy to two different models by comparing their R-squared values\n",
    "    - We can remove different variables from our model, recompute the R-squared value without the variable, and see whether the accuracy improves\n",
    "        - If our reduced model has a vastly different R-squared value, we know that the removed variable greatly contributes to the accuracy (or lack thereof) of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's calculate the baseline R-squared value for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406077428649428"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression = linear_model.LinearRegression(normalize=False, fit_intercept=True)\n",
    "baseline_R2 = r2_score(y, linear_regression.fit(X,y).predict(X))\n",
    "baseline_R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have the baseline level, we can loop through the features of the model to see the impact of removing each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.0566556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>0.0436813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>0.0288542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.0279973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.0114384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.0111941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.00645897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.00602173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0.00566654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>0.00565892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>0.00513338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>6.06634e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>1.70407e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Difference\n",
       "LSTAT      0.0566556\n",
       "RM         0.0436813\n",
       "DIS        0.0288542\n",
       "PTRATIO    0.0279973\n",
       "NOX        0.0114384\n",
       "RAD        0.0111941\n",
       "B         0.00645897\n",
       "ZN        0.00602173\n",
       "TAX       0.00566654\n",
       "CRIM      0.00565892\n",
       "CHAS      0.00513338\n",
       "INDUS    6.06634e-05\n",
       "AGE      1.70407e-06"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_R2 = pd.DataFrame(index = X.columns, columns = ['Difference'])\n",
    "\n",
    "for variable in X.columns:\n",
    "    cols = [x for x in X.columns if x!=variable]\n",
    "    X_temp = X[cols].copy()\n",
    "    R2 = r2_score(y, linear_regression.fit(X_temp,y).predict(X_temp))\n",
    "    difference = baseline_R2 - R2\n",
    "    df_R2.loc[variable, 'Difference'] = difference\n",
    "df_R2.sort_values('Difference', ascending = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This dataframe essentially ranks the importance of each variable in our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Note**: this doesn't mean the component each variable contributes to the R-squared value\n",
    "    - That would only be true if there was no correlation between the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are more sophisticated ways to gauge the importance of each variable, but the techniques of i) ranking standardized coefficients and ii) calculating parial R-squared values should be sufficient in most cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowing the impact of each variable on the model allows us to:\n",
    "\n",
    "1. Attempt to explain the results in a reasonable and understandable way\n",
    "\n",
    "2. Prioritize our work (datacleaning, preparation, transformation, etc.) by reducing the variables to the most relevant ones\n",
    "\n",
    "3. Conserve resources (e.g. memory) by reducing the data used in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "# Interaction models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The beta coefficients in a linear regression model tell us the change in the target variable after a single unit change of the predictor variable\n",
    "    - In a linear regression, this means that we're assuming that the changes are:\n",
    "        1. Constant\n",
    "        2. Unidirectional\n",
    "            - i.e. if the beta coefficient is positive, increasing the predictor can only increase the target, all else equal\n",
    "            \n",
    "- Although this is usually a good approximation, it's still a simplification\n",
    "    - The good news is that we have tricks to improve the approximation\n",
    "    \n",
    "- We can improve our linear regression by transforming predictor variables in different ways\n",
    "\n",
    "- We can measure the improvements using partial R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "# Discovering interactions\n",
    "\n",
    "- The first source of non-linearity that we'll consider is cause by **interactions between the predictors**\n",
    "    - This means that if variables $a$ and $b$ interact with eachother, the impact of varible $b$ on the target variable depends on the value of $a$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we have a model with two interacting predictors, we can analyze their interaction using the following formulation:\n",
    "\n",
    "# $\\hat{y} = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2} + \\beta_{12}x_{1}x_{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of interaction in a regression model\n",
    "\n",
    "- Target Variable: test driver satisfaction with car\n",
    "- Predictor Variable 1: car price\n",
    "- Predictor Variable 2: loudness of engine\n",
    "\n",
    "- Interaction between variables: if the car is loud but the price is low, the satisfaction will be low\n",
    "    - **However, if the car is loud and the price is HIGH, the satisfaction will be high**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Handling interactions between variables is actually much easier than we'd guess\n",
    "    - We simply need to transform a variable's role in the regression to account for the other interacting variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ways to find interacting variables\n",
    "\n",
    "1. Domain knowledge\n",
    "    - This means having an intuitive understanding of the model and predicting where the interactions will occur\n",
    "    \n",
    "2. Automatic search over possible combinations\n",
    "    - These combinations are tested with statistical measures like R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can look at automatic search in action using `PolynomialFeatures` from scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_interactions = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above, the `degree` parameter defines how many variables are interacting\n",
    "    - With the `degree` parameter set to 2, we say that the interaction is a **two-way effect**\n",
    "        - If we had set it to 3, it would be a **three-way effect**, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We've already calculated our baseline R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406077428649428"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we create a new input data matrix\n",
    "    - This accounts for the interaction effects of all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xi = create_interactions.fit_transform(X)\n",
    "main_effects = create_interactions.n_input_features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, we create a new linear regression model for each interaction\n",
    "    - We compare each new model's R-squared value to the baseline R-squared\n",
    "        - If the new model improves on the old one past a certain threshold (that we define), we take a deeper look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable 1</th>\n",
       "      <th>Variable 2</th>\n",
       "      <th>Improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>CHAS</td>\n",
       "      <td>0.010573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>RM</td>\n",
       "      <td>0.020845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZN</td>\n",
       "      <td>RM</td>\n",
       "      <td>0.013148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>RM</td>\n",
       "      <td>0.038212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>DIS</td>\n",
       "      <td>0.013227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NOX</td>\n",
       "      <td>RM</td>\n",
       "      <td>0.027250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RM</td>\n",
       "      <td>AGE</td>\n",
       "      <td>0.023789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RM</td>\n",
       "      <td>DIS</td>\n",
       "      <td>0.018481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RM</td>\n",
       "      <td>RAD</td>\n",
       "      <td>0.049087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RM</td>\n",
       "      <td>TAX</td>\n",
       "      <td>0.053748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RM</td>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>0.041241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RM</td>\n",
       "      <td>B</td>\n",
       "      <td>0.019729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RM</td>\n",
       "      <td>LSTAT</td>\n",
       "      <td>0.064221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable 1 Variable 2  Improvement\n",
       "0        CRIM       CHAS     0.010573\n",
       "1        CRIM         RM     0.020845\n",
       "2          ZN         RM     0.013148\n",
       "3       INDUS         RM     0.038212\n",
       "4       INDUS        DIS     0.013227\n",
       "5         NOX         RM     0.027250\n",
       "6          RM        AGE     0.023789\n",
       "7          RM        DIS     0.018481\n",
       "8          RM        RAD     0.049087\n",
       "9          RM        TAX     0.053748\n",
       "10         RM    PTRATIO     0.041241\n",
       "11         RM          B     0.019729\n",
       "12         RM      LSTAT     0.064221"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.01\n",
    "df_interactions = pd.DataFrame(columns = ['Variable 1', 'Variable 2', 'Improvement'])\n",
    "\n",
    "for i, effect in enumerate(create_interactions.powers_[(main_effects):]):\n",
    "    termA, termB = np.array(variables)[effect==1]\n",
    "    list_range = list(range(main_effects))+[main_effects + i]\n",
    "    Xi_temp = Xi[:,list_range]\n",
    "    R2_temp = r2_score(y, linear_regression.fit(Xi_temp,y).predict(Xi_temp))\n",
    "    difference = R2_temp - baseline_R2\n",
    "    \n",
    "    if difference > threshold:\n",
    "        series_temp = pd.Series([termA, termB, difference], index = df_interactions.columns)\n",
    "        df_interactions = df_interactions.append(series_temp, ignore_index = True)\n",
    "\n",
    "df_interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see from the dataframe above, the `RM` variable takes part in most of the interactions\n",
    "\n",
    "#### The highest improvement came from accounting for the interaction between `RM` and `LSTAT`\n",
    "\n",
    "### We can add this interaction to our model by adding a variable to our $X$ matrix by taking the product of `RM` and `LSTAT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xi = X.copy()\n",
    "Xi['interaction'] = Xi['RM']*Xi['LSTAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_R2 = r2_score(y, linear_regression.fit(Xi, y).predict(Xi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7406077428649428, 0.804828866568075)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_R2, improved_R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see, adding the new variable improved our model quite a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "# Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Polynomial expansion takes our interaction analysis to the next step\n",
    "    - We can use it to create both interactions, and non-linear power transformations from the original variables\n",
    "    \n",
    "- Power transformations bend the line of best fit\n",
    "    - The higher the degree for the transformation, the more bends in the line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - simple regression\n",
    "\n",
    "- Let's say we have a simple linear regression model defined as:\n",
    "\n",
    "# $\\hat{y} = \\beta_{0} + \\beta_{1}x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we add a second degree (aka quadratic) transformation, the model becomes:\n",
    "\n",
    "# $\\hat{y} = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we add onto this a third degree (aka cubic) transformation, the model becomes:\n",
    "\n",
    "# $\\hat{y} = \\beta_{0} + \\beta_{1}x + \\beta_{2}x^{2} + \\beta_{3}x^{3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - multiple regression\n",
    "\n",
    "- Now, let's say we have two variables in our regression model:\n",
    "\n",
    "# $\\hat{y} = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We we add a quadratic transformation, we don't simply add one term for each variable (we need to account for the interaction as well):\n",
    "\n",
    "# $\\hat{y} = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2} + \\beta_{3}x_{1}x_{2} + \\beta_{4}x_{1}^{2} + \\beta_{5}x_{2}^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see, expanding the model through transformation can create many new terms\n",
    "\n",
    "#### As we increase the power of the transformations, the model can become unstable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "\n",
    "# Testing linear vs. cubic transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
